{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f37abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import Vocabulary, HWDBDatasetHelper, ArchivedHWDBReader\n",
    "\n",
    "# your path to data\n",
    "train_path = r'/DATA/asaginbaev/HWDB/HWDBTrain/Images.zip'\n",
    "test_path = r'/DATA/asaginbaev/HWDB/HWDBTest/Images.zip'\n",
    "gt_path = './gt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d8b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63363b1f",
   "metadata": {},
   "source": [
    "В общем-то никакого рокет сайнса, в качестве модели взял resnet-18 с модифицированным классификатором и входной сверткой + возвращаю из модели вход классификатора, чтобы использовать ArcFace, изначально прогнал 5 эпох на трейн сплите получилась точность порядка 83%. 5 эпох взял так как эпоха по 6 часов занимала, и задача была посмотреть насколько вообще рабочая модель. Чтобы обучить уже основательно, распаковал всю трейн часть и использовал ImageFolder в качестве датасета. Скорость заметно увеличилась, что можно увидеть ниже. Не придумал как в случае с ImageFolder провернуть разбиение на валидацию и трейн, поэтому решил обучить модель на всей трейн части ради интереса, тем более что +20% данных в трейн сплите- это довольно весомо, обучал 15 эпох, ну и accuracy получилось порядка 93%. Также отказался от простого ресайза к 32 х 32 в пользу пропорционального ресайза картинки до размера, при котором большая сторона равна 64 и паддинга другой стороны до 64, чтобы сохранить исходные пропорции. Чекпоинты с первого и второго из упомянутых выше ранов приложены под именами \"checkpoint_solution_1.pth\" и \"checkpoint_solution_2.pth\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f84ab",
   "metadata": {},
   "source": [
    "### Data tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7f882df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reader = ArchivedHWDBReader(train_path)\n",
    "train_reader.open()\n",
    "train_helper = HWDBDatasetHelper(train_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "35cf8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_helper, val_helper = train_helper.train_val_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "92eb367e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2578433, 644609)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_helper.size(), val_helper.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7fa6001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from itertools import permutations\n",
    "import zipfile\n",
    "from typing import Optional, List\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from pytorch_metric_learning import losses\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28836219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_transform(img):\n",
    "    img = np.array(PIL.ImageOps.grayscale(img))\n",
    "    img_shape = np.array(img.shape)\n",
    "    new_size = np.array([64, 64])\n",
    "    intermediate_size = (64 * img_shape / max(img_shape)).astype(int)\n",
    "    pad_size = new_size - intermediate_size\n",
    "    side_pad_size = np.array([pad_size // 2, pad_size - pad_size // 2]).T\n",
    "        \n",
    "    return np.pad((cv2.resize(img, intermediate_size[::-1]) - 127.5) / 255., side_pad_size, constant_values=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b9e0c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder('/DATA/asaginbaev/HWDB/HWDBTrainUnzipped/CASIA-HWDB_Train/Train',\n",
    "                                                 transform=image_transform)\n",
    "#val_dataset = HWDBDataset(val_helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6636f",
   "metadata": {},
   "source": [
    "### Model & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7c02cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetWrapper(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(ResNetWrapper, self).__init__()\n",
    "        self.net = torchvision.models.resnet18(weights=None)\n",
    "        self.net.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.net.fc = nn.Identity()\n",
    "        self.fc = nn.Linear(512, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embs = self.net(x)\n",
    "        return self.fc(embs), embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c3e80256",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetWrapper(train_helper.vocabulary.num_classes())\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b43fb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d357b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1c9fe9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True, num_workers=32)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "127e1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_metric = losses.ArcFaceLoss(train_helper.vocabulary.num_classes(), 512,)\n",
    "loss_metric = loss_metric.cuda()\n",
    "optim_metric = torch.optim.Adam(loss_metric.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5c09f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def run_validation(val_loader: DataLoader, model: nn.Module, n_steps=None):\n",
    "    model.eval()\n",
    "    n_good = 0\n",
    "    n_all = 0\n",
    "    wrapper = lambda x: x\n",
    "    if n_steps is None:\n",
    "        n_steps = len(val_loader)\n",
    "        wrapper = tqdm\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(wrapper(val_loader)):\n",
    "            if batch == n_steps:\n",
    "                break\n",
    "            logits = model(X.unsqueeze(1).to(torch.float32).cuda())[0]\n",
    "            classes = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            n_good += sum(classes == y.cpu().numpy())\n",
    "            n_all += len(classes)\n",
    "    \n",
    "    return n_good / n_all\n",
    "\n",
    "\n",
    "def train_epoch(train_loader: DataLoader, model: nn.Module, optim, loss_fn, metric_loss, optim_loss):\n",
    "    for batch, (X, y) in enumerate(tqdm(train_loader)):\n",
    "        model.train()\n",
    "        logits, embs = model(X.unsqueeze(1).to(torch.float32).cuda())\n",
    "        loss = loss_fn(logits, y.to(torch.long).cuda()) + metric_loss(embs, y.to(torch.long).cuda())\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d5fd44e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [2:56:47<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [19:58<00:00, 21.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [14:44<00:00, 28.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [16:37<00:00, 25.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [15:05<00:00, 27.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [14:34<00:00, 28.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [14:42<00:00, 28.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [15:21<00:00, 27.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [15:01<00:00, 27.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [14:57<00:00, 28.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [15:11<00:00, 27.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [15:29<00:00, 27.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [15:10<00:00, 27.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [14:34<00:00, 28.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25180/25180 [15:23<00:00, 27.28it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    print(f'Epoch {epoch}:')\n",
    "    train_epoch(train_loader, model, optim, loss_fn, loss_metric, optim_metric)\n",
    "    torch.save(model.state_dict(), f'baseline_epoch{epoch}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de4c7b6",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "73dd6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r'/DATA/asaginbaev/HWDB/HWDBTest/Images.zip'\n",
    "pred_path = './pred.txt'\n",
    "\n",
    "test_reader = ArchivedHWDBReader(test_path)\n",
    "test_reader.open()\n",
    "test_helper = HWDBDatasetHelper(test_reader, prefix='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "71d47be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = HWDBDataset(test_helper)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0304466b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48533/48533 [09:35<00:00, 84.36it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X, _ in tqdm(test_loader):\n",
    "        logits = model(X.unsqueeze(1).to(torch.float32).cuda())[0]\n",
    "        classes = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        preds.extend(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "34ee1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pred_path, 'w') as f_pred:\n",
    "    for idx, pred in enumerate(preds):\n",
    "        name = test_helper.namelist[idx]\n",
    "        cls = train_helper.vocabulary.class_by_index(pred)\n",
    "        print(name, cls, file=f_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e70e25ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from course_ocr_t2.evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4c3c14ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9383598425288111"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(gt_path, pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "00a77389",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint_solution_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3b3d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
